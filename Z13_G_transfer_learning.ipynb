{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.callbacks import History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"Grafika/transfer_learning.png\" width=\"550\">\n",
    "\n",
    "**Transfer learning** (transfer \"wiedzy\") - wykorzystanie nauczonych przez kogoś sieci do naszego problemu. Możliwe dzięki temu, że cechy wykrywane przez sieci w głębokich warstwach mogą być uniwersalne i przydatne w różnych problemach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "base_model = VGG16(weights='imagenet',include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 149, 149, 32  864         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 149, 149, 32  96         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 149, 149, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 147, 147, 32  9216        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 147, 147, 32  96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 147, 147, 64  18432       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 147, 147, 64  192        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 73, 73, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 73, 73, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 71, 71, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 35, 35, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 35, 35, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 35, 35, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 35, 35, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_5 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 35, 35, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 35, 35, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 35, 35, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 35, 35, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 35, 35, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 35, 35, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 35, 35, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 35, 35, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 35, 35, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 35, 35, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 35, 35, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 35, 35, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 35, 35, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 35, 35, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 35, 35, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 35, 35, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 35, 35, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 35, 35, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 35, 35, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 35, 35, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 35, 35, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 35, 35, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 35, 35, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 35, 35, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 35, 35, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 35, 35, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 17, 17, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 17, 17, 96)   82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 17, 17, 96)  288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 17, 17, 96)   0           ['batch_normalization_29[0][0]'] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0          ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 17, 17, 768)  0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 17, 17, 128)  384        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 17, 17, 128)  384        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 17, 17, 128)  384        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 17, 17, 128)  384        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 17, 17, 128)  384        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 17, 17, 128)  384        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 17, 17, 768)  0          ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 17, 17, 192)  576        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 17, 17, 192)  576        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 17, 17, 192)  576        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 17, 17, 192)  576        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 17, 17, 768)  0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 17, 17, 160)  480        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 17, 17, 160)  480        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 17, 17, 160)  480        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 17, 17, 160)  480        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 17, 17, 160)  480        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 17, 17, 160)  480        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 17, 17, 768)  0          ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 17, 17, 192)  576        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 17, 17, 192)  576        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 17, 17, 192)  576        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 17, 17, 192)  576        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 17, 17, 768)  0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 17, 17, 160)  480        ['conv2d_54[0][0]']              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 17, 17, 160)  480        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 17, 17, 160)  480        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 17, 17, 160)  480        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 17, 17, 160)  480        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 17, 17, 160)  480        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 17, 17, 768)  0          ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 17, 17, 192)  576        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 17, 17, 192)  576        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 17, 17, 192)  576        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 17, 17, 192)  576        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 17, 17, 768)  0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 17, 17, 192)  576        ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_64[0][0]']          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 17, 17, 192)  576        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 17, 17, 192)  576        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 17, 17, 192)  576        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 17, 17, 192)  576        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 17, 17, 192)  576        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 17, 17, 768)  0          ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 17, 17, 192)  576        ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 17, 17, 192)  576        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 17, 17, 192)  576        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 17, 17, 192)  576        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 17, 17, 768)  0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 17, 17, 192)  576        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 17, 17, 192)  576        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_73[0][0]'] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 17, 17, 192)  576        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 17, 17, 192)  576        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 8, 8, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 8, 8, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 8, 8, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 8, 8, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 8, 8, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 8, 8, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 8, 8, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 8, 8, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 8, 8, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 8, 8, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_76 (BatchN  (None, 8, 8, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 8, 8, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 8, 8, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8, 8, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 8, 8, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 8, 8, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 8, 8, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 8, 8, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 8, 8, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 8, 8, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 8, 8, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_88[0][0]'] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 8, 8, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 8, 8, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 8, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 8, 8, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['mixed10[0][0]']                \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 1000)         2049000     ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,851,784\n",
      "Trainable params: 23,817,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inc = InceptionV3()\n",
    "inc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Trzeba nadać wymiar wejści anaszej sieci\n",
    "```python\n",
    "h,w = 150, 150\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w = 150, 150\n",
    "model = VGG16(weights='imagenet',include_top=False,input_shape=(h,w,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad \n",
    "Zbudujmy siec z \n",
    "* VGG16 dla wejścia h,w = 150, 150\n",
    "* Flatten\n",
    "* Dense\n",
    "* Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 1)                 2097665   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 2,097,665\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "h,w = 150, 150\n",
    "model = VGG16(weights='imagenet',include_top=False,input_shape=(h,w,3))\n",
    "\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_transfer = Sequential()\n",
    "model_transfer.add(model)\n",
    "model_transfer.add(top_model)\n",
    "\n",
    "model_transfer.layers[0].trainable = False\n",
    "\n",
    "model_transfer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "# top_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Naucz model \n",
    " \n",
    "* użyj Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n",
      "Found 10 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "model_transfer.compile(loss='binary_crossentropy',optimizer=\"sgd\",metrics=['accuracy'])\n",
    "\n",
    "train_data_dir = r'Dane\\data\\train'\n",
    "validation_data_dir = r'Dane\\data\\validation'\n",
    "nb_validation_samples = 200\n",
    "nb_train_samples = 50\n",
    "epochs = 50\n",
    "batch_size = 10\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   shear_range=0.2, \n",
    "                                   zoom_range=0.2,\n",
    "                                   rotation_range=45, \n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir, \n",
    "                                                    target_size=(h, w), \n",
    "                                                    batch_size=batch_size, \n",
    "                                                    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                        target_size=(h, w), \n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps =nb_validation_samples//batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1824 - accuracy: 0.9450WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 10s 496ms/step - loss: 0.1824 - accuracy: 0.9450\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1520 - accuracy: 0.9300WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 11s 542ms/step - loss: 0.1520 - accuracy: 0.9300\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2370 - accuracy: 0.9050WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 11s 564ms/step - loss: 0.2370 - accuracy: 0.9050\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2147 - accuracy: 0.9150WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 11s 559ms/step - loss: 0.2147 - accuracy: 0.9150\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1612 - accuracy: 0.9350WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 12s 594ms/step - loss: 0.1612 - accuracy: 0.9350\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1823 - accuracy: 0.9300WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 12s 589ms/step - loss: 0.1823 - accuracy: 0.9300\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1803 - accuracy: 0.9300WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 12s 593ms/step - loss: 0.1803 - accuracy: 0.9300\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1838 - accuracy: 0.9350WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 12s 608ms/step - loss: 0.1838 - accuracy: 0.9350\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.9600WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 13s 662ms/step - loss: 0.1190 - accuracy: 0.9600\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1261 - accuracy: 0.9500WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 17s 841ms/step - loss: 0.1261 - accuracy: 0.9500\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2968 - accuracy: 0.9050WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 11s 568ms/step - loss: 0.2968 - accuracy: 0.9050\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1356 - accuracy: 0.9500WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 12s 595ms/step - loss: 0.1356 - accuracy: 0.9500\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0952 - accuracy: 0.9850WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 12s 619ms/step - loss: 0.0952 - accuracy: 0.9850\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1230 - accuracy: 0.9450WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 12s 598ms/step - loss: 0.1230 - accuracy: 0.9450\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2820 - accuracy: 0.8750WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 12s 592ms/step - loss: 0.2820 - accuracy: 0.8750\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1671 - accuracy: 0.9300WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 13s 649ms/step - loss: 0.1671 - accuracy: 0.9300\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.9700WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 12s 617ms/step - loss: 0.1095 - accuracy: 0.9700\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1345 - accuracy: 0.9400WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 12s 604ms/step - loss: 0.1345 - accuracy: 0.9400\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2808 - accuracy: 0.8850WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 13s 631ms/step - loss: 0.2808 - accuracy: 0.8850\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1297 - accuracy: 0.9600WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 13s 626ms/step - loss: 0.1297 - accuracy: 0.9600\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.9850WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 13s 641ms/step - loss: 0.0853 - accuracy: 0.9850\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1446 - accuracy: 0.9500WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 12s 616ms/step - loss: 0.1446 - accuracy: 0.9500\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.9500WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 12s 611ms/step - loss: 0.1332 - accuracy: 0.9500\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2048 - accuracy: 0.9000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 13s 635ms/step - loss: 0.2048 - accuracy: 0.9000\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1465 - accuracy: 0.9500WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 12s 615ms/step - loss: 0.1465 - accuracy: 0.9500\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1440 - accuracy: 0.9450WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 12s 590ms/step - loss: 0.1440 - accuracy: 0.9450\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 0.1711 - accuracy: 0.9150WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 12s 614ms/step - loss: 0.1711 - accuracy: 0.9150\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1872 - accuracy: 0.9350WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 22s 1s/step - loss: 0.1872 - accuracy: 0.9350\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1228 - accuracy: 0.9550WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 22s 1s/step - loss: 0.1228 - accuracy: 0.9550\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.9550WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 22s 1s/step - loss: 0.0986 - accuracy: 0.9550\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1371 - accuracy: 0.9300WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "20/20 [==============================] - 23s 1s/step - loss: 0.1371 - accuracy: 0.9300\n",
      "Epoch 32/50\n",
      "11/20 [===============>..............] - ETA: 9s - loss: 0.1122 - accuracy: 0.9727 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13284/3940035676.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mhistory_tr_ag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHistory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m model_transfer.fit(train_generator, epochs=epochs, \n\u001b[0m\u001b[0;32m      4\u001b[0m                     validation_data=validation_generator, callbacks=[early_stopping, history_tr_ag])\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_tr_ag = History()\n",
    "early_stopping = EarlyStopping(patience=3,monitor=\"val_loss\")\n",
    "model_transfer.fit(train_generator, epochs=epochs, \n",
    "                    validation_data=validation_generator, callbacks=[early_stopping, history_tr_ag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13284/402142327.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory_tr_ag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"tarina Adam\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory_tr_ag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"test Adam\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_tr_ag.history['accuracy'], label = \"tarina Adam\")\n",
    "plt.plot(history_tr_ag.history['val_accuracy'], label = \"test Adam\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Wykonaj zadania na większym zbiorze danych.\n",
    "\n",
    "https://www.microsoft.com/en-us/download/details.aspx?id=54765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sou\\AppData\\Local\\Temp/ipykernel_13284/1469862599.py:32: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model_transfer.fit_generator(train_generator, steps_per_epoch=batch_size, epochs=epochs,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 0.2842 - accuracy: 0.9000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 6s 517ms/step - loss: 0.2842 - accuracy: 0.9000\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3345 - accuracy: 0.8400WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 5s 526ms/step - loss: 0.3345 - accuracy: 0.8400\n",
      "Epoch 3/50\n",
      " 7/10 [====================>.........] - ETA: 1s - loss: 0.4579 - accuracy: 0.7857"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13284/1469862599.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mhistory_tr_ag2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHistory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m model_transfer.fit_generator(train_generator, steps_per_epoch=batch_size, epochs=epochs, \n\u001b[0m\u001b[0;32m     33\u001b[0m                     validation_data=validation_generator, validation_steps=batch_size, callbacks=[early_stopping, history_tr_ag2])\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2207\u001b[0m         \u001b[1;34m'Please use `Model.fit`, which supports generators.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2208\u001b[0m         stacklevel=2)\n\u001b[1;32m-> 2209\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   2210\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2211\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_transfer.compile(loss='binary_crossentropy',optimizer=\"sgd\",metrics=['accuracy'])\n",
    "\n",
    "train_data_dir = './Dane/data/PetImages'\n",
    "validation_data_dir = './Dane/data/validation'\n",
    "nb_validation_samples = 200\n",
    "nb_train_samples = 50\n",
    "epochs = 50\n",
    "batch_size = 10\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   shear_range=0.2, \n",
    "                                   zoom_range=0.2,\n",
    "                                   rotation_range=45, \n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir, \n",
    "                                                    target_size=(h, w), \n",
    "                                                    batch_size=batch_size, \n",
    "                                                    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                        target_size=(h, w), \n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='binary')\n",
    "\n",
    "history_tr_ag2 = History()\n",
    "early_stopping = EarlyStopping(patience=3,monitor=\"val_loss\")\n",
    "model_transfer.fit_generator(train_generator, steps_per_epoch=batch_size, epochs=epochs, \n",
    "                    validation_data=validation_generator, validation_steps=10, callbacks=[early_stopping, history_tr_ag2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
